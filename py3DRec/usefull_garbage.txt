#k = np.mat(([[ 683.39404297,    0.        ,  267.21336591], [   0.        ,  684.3449707 ,  218.56421036],  [   0.        ,    0.        ,    1.        ]]))

#pt = np.array([[ -50.0000 , 0.0000, 450.0000], 
#[ -50.0000 , 0.0000, 550.0000], 
#[ 50.0000 , 0.0000, 550.0000], 
#[ 50.0000 , 0.0000, 450.0000], 
#[ -50.0000 , 0.0000, 450.0000], 
#[ -50.0000 , 50.0000, 450.0000], 
#[ -50.0000 , 50.0000, 550.0000], 
#[ 50.0000 , 50.0000, 550.0000], 
#[ 50.0000 , 50.0000, 450.0000], 
#[ -50.0000 , 50.0000, 450.0000], 
#[ -25.0000 , 50.0000, 475.0000], 
#[ -25.0000 , 50.0000, 525.0000], 
#[ 25.0000 , 50.0000, 525.0000], 
#[ 25.0000 , 50.0000, 475.0000], 
#[ -25.0000 , 50.0000, 475.0000], 
#[ -25.0000 , 75.0000, 475.0000], 
#[ -25.0000 , 75.0000, 525.0000], 
#[ 25.0000 , 75.0000, 525.0000], 
#[ 25.0000 , 75.0000, 475.0000], 
#[ -25.0000 , 75.0000, 475.0000], 
#[ -23.7500 , 80.0000, 476.2500], 
#[ -23.7500 , 80.0000, 523.7500], 
#[ 23.7500 , 80.0000, 523.7500], 
#[ 23.7500 , 80.0000, 476.2500], 
#[ -23.7500 , 80.0000, 476.2500], 
#[ -22.5625 , 85.0000, 477.4375], 
#[ -22.5625 , 85.0000, 522.5625], 
#[ 22.5625 , 85.0000, 522.5625], 
#[ 22.5625 , 85.0000, 477.4375], 
#[ -22.5625 , 85.0000, 477.4375], 
#[ -21.4344 , 90.0000, 478.5656], 
#[ -21.4344 , 90.0000, 521.4344], 
#[ 21.4344 , 90.0000, 521.4344], 
#[ 21.4344 , 90.0000, 478.5656], 
#[ -21.4344 , 90.0000, 478.5656], 
#[ -20.3627 , 95.0000, 479.6373], 
#[ -20.3627 , 95.0000, 520.3627], 
#[ 20.3627 , 95.0000, 520.3627], 
#[ 20.3627 , 95.0000, 479.6373], 
#[ -20.3627 , 95.0000, 479.6373], 
#[ -19.3445 , 100.0000, 480.6555], 
#[ -19.3445 , 100.0000, 519.3445], 
#[ 19.3445 , 100.0000, 519.3445], 
#[ 19.3445 , 100.0000, 480.6555], 
#[ -19.3445 , 100.0000, 480.6555], 
#[ -18.3773 , 105.0000, 481.6227], 
#[ -18.3773 , 105.0000, 518.3773], 
#[ 18.3773 , 105.0000, 518.3773], 
#[ 18.3773 , 105.0000, 481.6227], 
#[ -18.3773 , 105.0000, 481.6227], 
#[ -17.4584 , 110.0000, 482.5416], 
#[ -17.4584 , 110.0000, 517.4584], 
#[ 17.4584 , 110.0000, 517.4584], 
#[ 17.4584 , 110.0000, 482.5416], 
#[ -17.4584 , 110.0000, 482.5416], 
#[ -16.5855 , 115.0000, 483.4145], 
#[ -16.5855 , 115.0000, 516.5855], 
#[ 16.5855 , 115.0000, 516.5855], 
#[ 16.5855 , 115.0000, 483.4145], 
#[ -16.5855 , 115.0000, 483.4145], 
#[ -15.7562 , 120.0000, 484.2438], 
#[ -15.7562 , 120.0000, 515.7562], 
#[ 15.7562 , 120.0000, 515.7562], 
#[ 15.7562 , 120.0000, 484.2438], 
#[ -15.7562 , 120.0000, 484.2438], 
#[ -14.9684 , 125.0000, 485.0316], 
#[ -14.9684 , 125.0000, 514.9684], 
#[ 14.9684 , 125.0000, 514.9684], 
#[ 14.9684 , 125.0000, 485.0316], 
#[ -14.9684 , 125.0000, 485.0316]])

#Reconstruction.clsReconstruction.saveData(pt,'pt_test.dat')

#Reconstruction.clsReconstruction.saveData(k,'k_cam_hp.dat')



#sift = cv2.xfeatures2d.SIFT_create()
		#sift.compute(

		#dense=cv2.FeatureDetector_create('Dense')
		
		#freak = cv2.xfeatures2d.FREAK_create()
		#kp_f1, des_f1 = freak.detectAndCompute(im_1,None)
		#kp_f2, des_f2 = freak.detectAndCompute(im_2,None)

		#bf = cv2.BFMatcher()
		#matches = bf.knnMatch(des_1,des_2,k=2)
		#good = []
		#for m,n in matches:
		#	if m.distance < 0.4*n.distance:
		#		good.append([m])

		#img3 = cv2.drawMatchesKnn(im_1,kp_1,im_2,kp_2,good,im_1,flags=2)

		#plt.imshow(img3),plt.show()

		

				
		##select points to evaluate the fundamental matrix
		#Pts1 = []
		#Pts2 = []
		#Tg = []
		#dx = im_1.shape[1]

		#for i in matches:
		#	p1 = kp_1[i.queryIdx].pt
		#	p2 = kp_2[i.trainIdx].pt
		#	Pts1.append(p1)
		#	Pts2.append(p2)
		#	tg = np.arctan2(p2[0] - p1[0],dx + p2[1] - p1[1])
		#	Tg.append(tg)

		#		#get the grid to project onto
		#x_grid = np.linspace(-np.pi/3, np.pi/3, 90)
		#vTg = np.array(Tg)
		##evaluate the KDEpdf
		#kde_pdf = stats.gaussian_kde(vTg).evaluate(x_grid)
		#xmax = x_grid[kde_pdf.argmax()]




		

	@staticmethod
	def returnMatching(im_1,im_2, ndraw):
		im_1 = cv2.cvtColor(im_1, cv2.COLOR_BGR2GRAY)
		im_2 = cv2.cvtColor(im_2, cv2.COLOR_BGR2GRAY)
		#cv2.imshow('trilho',im_1)

		orb = cv2.ORB_create()
		fast = cv2.FastFeatureDetector_create()

		kp_1, des_1 = orb.detectAndCompute(im_1,None)
		kp_2, des_2 = orb.detectAndCompute(im_2,None)

		bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

		matches = bf.match(des_1,des_2)
		
		matches = sorted(matches, key = lambda x:x.distance)

		draw_params = dict(matchColor = (20,20,20), singlePointColor = (200,200,200),
							matchesMask = None,
							flags = 0)
		
		img3 = cv2.drawMatches(im_1,kp_1,im_2,kp_2,matches[0:ndraw], None, **draw_params)

		return kp_1,kp_2, des_1, des_2, matches, img3




  

	#=======================================
	@staticmethod
	def NewMatching(file1, file2, kdef): 

		k = np.mat(clsReconstruction.loadData(kdef))
		ki = np.linalg.inv(k)
		im_1 = cv2.imread(file1,0)
		im_2 = cv2.imread(file2,0)

		Xp_1, Xp_2 = clsReconstruction.getMatchingPointsFromObjects(im_1,im_2,k)

		d1 = 120
		d2 = 120
		indc = 1;
		idy1 = (max(0,int(Xp_1[indc][1])-d1), min(int(Xp_1[indc][1])+d1,im_1.shape[1]))
		idx1 = (max(0,int(Xp_1[indc][0])-d1), min(int(Xp_1[indc][0])+d1,im_1.shape[0]))
		idy2 = (max(0,int(Xp_2[indc][1])-d2), min(int(Xp_2[indc][1])+d2,im_2.shape[1]))
		idx2 = (max(0,int(Xp_2[indc][0])-d2), min(int(Xp_2[indc][0])+d2,im_2.shape[0]))

		cut_1 = im_1[idy1[0]:idy1[1],idx1[0]:idx1[1]] 
		cut_2 = im_2[idy2[0]:idy2[1],idx2[0]:idx2[1]] 

		#plt.figure()
		#clsReconstruction.doSubPlot(plt,121,cut_1, cv2.COLOR_GRAY2RGB, 'cut 1') 
		#clsReconstruction.doSubPlot(plt,122,cut_2, cv2.COLOR_GRAY2RGB, 'cut 2')
		#plt.show()

		Xcp_1, Xcp_2 = clsReconstruction.getMatchingPointsFromObjects(cut_1,cut_2,k)
		M, mask = cv2.findHomography(Xcp_1, Xcp_2, cv2.RANSAC,5.0)

		

		if M is not None:
			result = cv2.warpPerspective(cut_1, M, (cut_2.shape[1] + cut_2.shape[1], im_2.shape[0]))
			erro = cut_2 - cut_2
			erro[0:cut_2.shape[0], 0:cut_2.shape[1]] = result[0:cut_2.shape[0], 0:cut_2.shape[1]] - cut_2
			result[0:cut_2.shape[0], 0:cut_2.shape[1]] = cut_2
			clsReconstruction.doSubPlot(plt,121,erro, cv2.COLOR_GRAY2RGB, 'parte 1')
			clsReconstruction.doSubPlot(plt,121,result, cv2.COLOR_GRAY2RGB, 'parte 1')
			plt.show()

		

		
	
			 

		matchesMask = mask.ravel().tolist()

		#calculo da entropia = baixa entropia significa pouca informacao para casar as imagens
		#areas com baixa entropia ou deverao ser ignoradas ou entram com pouco peso e os pixels
		#serao interpolados linearmente, mas sem peso no processo de homografia
		#pp = np.cov(cut1)
		#a,b = np.linalg.eig(pp)

		#pp2 = np.cov(cut2)
		#aa,bb = np.linalg.eig(pp2)
		


		#aqui visualiza os pontos capturados nas imagens
		cv2.circle(im_1,(int(pt1.pt[0]), int(pt1.pt[1])),int(4),(250,250,250),4,2)
		cv2.circle(im_2,(int(pt2.pt[0]), int(pt2.pt[1])),int(4),(250,50,250),4,2)


		#cv2.imshow('compilado',img3)
		#cv2.imshow('pt1',im_1)
		#cv2.imshow('pt2',im_2)
		#cv2.waitKey(0)
		#plt.figure()
		#plt.imshow(img3)
		#plt.show()
		#cv2.imshow('trilho',im)

		#plt.imshow(cv2.cvtColor(cut1,cv2.COLOR_GRAY2RGB))
		plt.figure(1)
		clsReconstruction.doSubPlot(plt,221,im_1, cv2.COLOR_GRAY2RGB, 'original 1')
		clsReconstruction.doSubPlot(plt,222,im_2, cv2.COLOR_GRAY2RGB, 'original 2')
		clsReconstruction.doSubPlot(plt,223,cut_1, cv2.COLOR_GRAY2RGB, 'parte 1')
		clsReconstruction.doSubPlot(plt,224,cut_2, cv2.COLOR_GRAY2RGB, 'parte 2')
		plt.show()

		#kp = fast.detect(im)
		#im2 = cv2.drawKeypoints(im_1, kp_1, im2, color=(255,0,0))
		#cv2.imshow('trilho22',im2)
		#cv2.imshow('trilho3',im2)
		cv2.waitKey(0)